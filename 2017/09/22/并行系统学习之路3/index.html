
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>并行系统学习之路（三） ---- CUDA学习 | Xingyao Huang&#39;s Blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Xingyao Huang">
    

    
    <meta name="description" content="NVIDIA CUDA 编程学习本篇我们来学习CUDA编程，首先我们明确一下几个名词的相互关系：  GPU:  Graphics processing unit GPU和CPU一样也是计算机的计算单位，但是他们的设计目标有很大不同，GPU专注于计算，它有有更多的ALU，而CPU为了处理各种计算机指令需要许多其他的复杂结构 GPU适合大规模并行计算，而CPU适合逻辑控制串行运算 CPU与GPU架构对">
<meta name="keywords" content="parallel system">
<meta property="og:type" content="article">
<meta property="og:title" content="并行系统学习之路（三） ---- CUDA学习">
<meta property="og:url" content="http://vulture29.github.io/2017/09/22/并行系统学习之路3/index.html">
<meta property="og:site_name" content="Xingyao Huang&#39;s Blog">
<meta property="og:description" content="NVIDIA CUDA 编程学习本篇我们来学习CUDA编程，首先我们明确一下几个名词的相互关系：  GPU:  Graphics processing unit GPU和CPU一样也是计算机的计算单位，但是他们的设计目标有很大不同，GPU专注于计算，它有有更多的ALU，而CPU为了处理各种计算机指令需要许多其他的复杂结构 GPU适合大规模并行计算，而CPU适合逻辑控制串行运算 CPU与GPU架构对">
<meta property="og:image" content="http://vulture29.github.io/content/images/2017/09/cpu_gpu_arch.png">
<meta property="og:image" content="http://vulture29.github.io/content/images/2017/09/thread_batching.png">
<meta property="og:image" content="http://vulture29.github.io/content/images/2017/09/cuda_memory.png">
<meta property="og:updated_time" content="2017-09-23T02:12:09.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="并行系统学习之路（三） ---- CUDA学习">
<meta name="twitter:description" content="NVIDIA CUDA 编程学习本篇我们来学习CUDA编程，首先我们明确一下几个名词的相互关系：  GPU:  Graphics processing unit GPU和CPU一样也是计算机的计算单位，但是他们的设计目标有很大不同，GPU专注于计算，它有有更多的ALU，而CPU为了处理各种计算机指令需要许多其他的复杂结构 GPU适合大规模并行计算，而CPU适合逻辑控制串行运算 CPU与GPU架构对">
<meta name="twitter:image" content="http://vulture29.github.io/content/images/2017/09/cpu_gpu_arch.png">

    
    <link rel="alternative" href="/atom.xml" title="Xingyao Huang&#39;s Blog" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/1.ico">
    
    
    <link rel="apple-touch-icon" href="/img/1.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/1.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Xingyao Huang&#39;s Blog">Xingyao Huang&#39;s Blog</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/">About</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="搜索" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2017/09/22/并行系统学习之路3/" title="并行系统学习之路（三） ---- CUDA学习" itemprop="url">并行系统学习之路（三） ---- CUDA学习</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="Xingyao Huang" target="_blank" itemprop="author">Xingyao Huang</a>
		
  <p class="article-time">
    <time datetime="2017-09-22T18:44:27.000Z" itemprop="datePublished"> 发表于 2017-09-22</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#NVIDIA-CUDA-编程学习"><span class="toc-number">1.</span> <span class="toc-text">NVIDIA CUDA 编程学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CUDA编程模型"><span class="toc-number">2.</span> <span class="toc-text">CUDA编程模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#线程分配"><span class="toc-number">2.1.</span> <span class="toc-text">线程分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA中的三种函数"><span class="toc-number">2.2.</span> <span class="toc-text">CUDA中的三种函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-模型下的内存空间分配"><span class="toc-number">2.3.</span> <span class="toc-text">CUDA 模型下的内存空间分配</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#调用Kernel函数实例"><span class="toc-number">2.4.</span> <span class="toc-text">调用Kernel函数实例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#硬件执行模型"><span class="toc-number">2.5.</span> <span class="toc-text">硬件执行模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Thread-Warps-Block-之间关系"><span class="toc-number">2.5.1.</span> <span class="toc-text">Thread, Warps, Block 之间关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">2.6.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实例-–-使用Leibniz公式求π值"><span class="toc-number">2.7.</span> <span class="toc-text">实例 – 使用Leibniz公式求π值</span></a></li></ol></li></ol>
		
		</div>
		
		<h1 id="NVIDIA-CUDA-编程学习"><a href="#NVIDIA-CUDA-编程学习" class="headerlink" title="NVIDIA CUDA 编程学习"></a>NVIDIA CUDA 编程学习</h1><p>本篇我们来学习CUDA编程，首先我们明确一下几个名词的相互关系：</p>
<ul>
<li><p>GPU:</p>
<ul>
<li>Graphics processing unit</li>
<li>GPU和CPU一样也是计算机的计算单位，但是他们的设计目标有很大不同，GPU专注于计算，它有有更多的ALU，而CPU为了处理各种计算机指令需要许多其他的复杂结构</li>
<li>GPU适合大规模并行计算，而CPU适合逻辑控制串行运算</li>
<li><p>CPU与GPU架构对比</p>
<p><img src="/content/images/2017/09/cpu_gpu_arch.png" alt=""></p>
</li>
</ul>
</li>
<li><p>GPGPU：</p>
<ul>
<li>General Purpose computation using GPU in applications(Other than 3D graphics)</li>
<li>通常我们说起GPU，总是会想起3D图形渲染相关的事物，其实我们也可以运用GPU的并行计算特性可以完成很多其他的工作，我们把这种方法称为GPGPU</li>
</ul>
</li>
<li><p>CUDA</p>
<ul>
<li>Compute Unified Device Architecture</li>
<li>CUDA是一个GPU编程模型，相当于一个开发者与GPU之间的接口，开发者使用CUDA可以写出在NVIDIA GPU上运行的并行程序</li>
<li>CPU称为Host，GPU称为Device</li>
</ul>
</li>
</ul>
<h1 id="CUDA编程模型"><a href="#CUDA编程模型" class="headerlink" title="CUDA编程模型"></a>CUDA编程模型</h1><ul>
<li>相当于CPU的协作处理器</li>
<li>拥有自己的DRAM</li>
<li>SIMD架构</li>
<li>GPU线程开销小，可以轻松执行多个线程</li>
</ul>
<h2 id="线程分配"><a href="#线程分配" class="headerlink" title="线程分配"></a>线程分配</h2><p><img src="/content/images/2017/09/thread_batching.png" alt=""></p>
<ul>
<li>每一个Kernel函数将会在包含多个线程block的grid中执行<ul>
<li>一个block中的所有线程共享memory</li>
</ul>
</li>
<li>一个block中的线程可以通过以下方法互相交流<ul>
<li><code>__syncthreads()</code>同步操作</li>
<li>通过shared memory进行数据分享</li>
</ul>
</li>
<li>两个不同block中的线程不能相互交流（除非使用全局memory，但是比较慢）</li>
<li>线程和block都有属于自己的ID</li>
</ul>
<h2 id="CUDA中的三种函数"><a href="#CUDA中的三种函数" class="headerlink" title="CUDA中的三种函数"></a>CUDA中的三种函数</h2><table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">执行地点</th>
<th style="text-align:left">调用地点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>__device__ float DeviceFunc()</code></td>
<td style="text-align:center">device</td>
<td style="text-align:left">device</td>
</tr>
<tr>
<td style="text-align:center"><code>__global__ void  KernelFunc()</code></td>
<td style="text-align:center">device</td>
<td style="text-align:left">host</td>
</tr>
<tr>
<td style="text-align:center"><code>__host__   float HostFunc()</code></td>
<td style="text-align:center">host</td>
<td style="text-align:left">host</td>
</tr>
</tbody>
</table>
<h2 id="CUDA-模型下的内存空间分配"><a href="#CUDA-模型下的内存空间分配" class="headerlink" title="CUDA 模型下的内存空间分配"></a>CUDA 模型下的内存空间分配</h2><p><img src="/content/images/2017/09/cuda_memory.png" alt=""></p>
<ul>
<li>每个线程可以<ul>
<li>R/W per-thread registers</li>
<li>R/W per-thread local memory</li>
<li>R/W per-block shared memory</li>
<li>R/W per-grid global memory</li>
<li>Read only per-grid constant memory</li>
<li>Read only per-grid texture memory</li>
</ul>
</li>
<li>host只可以读写global，constant以及texture的memory</li>
<li>Global memory<ul>
<li>host与device之间读写数据的主要方式</li>
<li>所有线程可见，只读</li>
</ul>
</li>
<li>Texture and Constant Memories<ul>
<li>host初始化的常量</li>
<li>所有线程可见，只读</li>
</ul>
</li>
</ul>
<h2 id="调用Kernel函数实例"><a href="#调用Kernel函数实例" class="headerlink" title="调用Kernel函数实例"></a>调用Kernel函数实例</h2><p>调用Kernel函数是必须指定config：</p>
<figure class="highlight lsl"><table><tr><td class="code"><pre><div class="line">__global__ void KernelFunc(...);</div><div class="line">dim3 DimGrid(<span class="number">100</span>, <span class="number">50</span>); <span class="comment">// 5000 thread blocks</span></div><div class="line">dim3 DimBlock(<span class="number">4</span>, <span class="number">8</span>, <span class="number">8</span>); <span class="comment">// 256 threads per block size_t SharedMemBytes = 64; // 64 bytes of shared memory KernelFunc&lt;&lt;&lt; DimGrid, DimBlock, SharedMemBytes &gt;&gt;&gt;(...);</span></div></pre></td></tr></table></figure>
<ul>
<li>所有Kernel函数调用都是异步的（除非显式堵塞）</li>
<li>Kernel函数允许递归</li>
</ul>
<p>下面是一个实例，该实例把一个数组里的所有值自增了1</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><div class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">incrArrayOnDevice</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">int</span> N)</span></span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">  <span class="keyword">int</span> idx = blockIdx.x*blockDim.x + threadIdx.x;</div><div class="line">  <span class="keyword">if</span> (idx&lt;N) a[idx] = a[idx]+<span class="number">1.f</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="keyword">float</span> *a_h, *a_d; <span class="keyword">int</span> i, N=<span class="number">10</span>;</div><div class="line">  <span class="keyword">size_t</span> size = N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>);</div><div class="line">  a_h = (<span class="keyword">float</span> *)<span class="built_in">malloc</span>(size);</div><div class="line">  <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;N; i++) a_h[i] = (<span class="keyword">float</span>)i;</div><div class="line"></div><div class="line">  <span class="comment">// allocate array on device</span></div><div class="line">  cudaMalloc((<span class="keyword">void</span> **) &amp;a_d, size);</div><div class="line"></div><div class="line">  <span class="comment">// copy data from host to device</span></div><div class="line">  cudaMemcpy(a_d, a_h, <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*N, cudaMemcpyHostToDevice);</div><div class="line"></div><div class="line">  <span class="comment">// do calculation on device:</span></div><div class="line">  <span class="comment">// Part 1 of 2. Compute execution configuration</span></div><div class="line">  <span class="keyword">int</span> blockSize = <span class="number">4</span>;</div><div class="line">  <span class="keyword">int</span> nBlocks = N/blockSize + (N%blockSize == <span class="number">0</span>?<span class="number">0</span>:<span class="number">1</span>);</div><div class="line"></div><div class="line">  <span class="comment">// Part 2 of 2. Call incrementArrayOnDevice kernel</span></div><div class="line">  incrArrayOnDevice &lt;&lt;&lt; nBlocks, blockSize &gt;&gt;&gt; (a_d, N);</div><div class="line"></div><div class="line">  <span class="comment">// Retrieve result from device and store in b_h</span></div><div class="line">  cudaMemcpy(a_h, a_d, <span class="keyword">sizeof</span>(<span class="keyword">float</span>)*N, cudaMemcpyDeviceToHost);</div><div class="line"></div><div class="line">  <span class="comment">// cleanup</span></div><div class="line">  <span class="built_in">free</span>(a_h);</div><div class="line">  cudaFree(a_d);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<!-- ## CUDA程序的编译过程
未仔细研究，待补充 -->
<h2 id="硬件执行模型"><a href="#硬件执行模型" class="headerlink" title="硬件执行模型"></a>硬件执行模型</h2><ul>
<li>在grid里，每一个block会被分成warp，每一个warp将由一个多处理器(SM)执行<ul>
<li>device每次只执行一个grid</li>
</ul>
</li>
<li>每一个block将由一个多处理器执行<ul>
<li>因此shared memory空间将位于on-chip shared memory，每个block可以共享</li>
</ul>
</li>
<li>一个多处理器可以同时执行多个block<ul>
<li>Shared memory 和寄存器空间是由根据所有同时运行的block来进行分配的</li>
<li>因此减少shared memory和寄存器的使用(一个block中的)会增加可以同时运行的block的数量</li>
</ul>
</li>
</ul>
<h3 id="Thread-Warps-Block-之间关系"><a href="#Thread-Warps-Block-之间关系" class="headerlink" title="Thread, Warps, Block 之间关系"></a>Thread, Warps, Block 之间关系</h3><ul>
<li>在一个warp中最多可以有32个线程(小于等于32)</li>
<li>一个block中最多有32个warp</li>
<li>每个block在一个SM中执行(因此每个warp也一样)</li>
<li>GF110有16个SMs</li>
<li>至少16个block可以保证”填满”device</li>
<li>越多效率提升越高<ul>
<li>如果有足够资源(寄存器，线程空间，Shared memory),一个SM可以执行多个block</li>
</ul>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>device = GPU = 所有SM</li>
<li>多处理器 =  许多处理器和对应shared memory的组合</li>
<li>Kernel = GPU 程序</li>
<li>Grid = 一组执行kernel的block</li>
<li>Block = 一组SIMD的线程，他们可以执行kernel function以及通过shared memory交流</li>
</ul>
<h2 id="实例-–-使用Leibniz公式求π值"><a href="#实例-–-使用Leibniz公式求π值" class="headerlink" title="实例 – 使用Leibniz公式求π值"></a>实例 – 使用Leibniz公式求π值</h2><figure class="highlight cpp"><table><tr><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"mytime.h"</span></span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> THREADS 512</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_BLOCKS 64</span></div><div class="line"></div><div class="line"><span class="comment">// find the nearest 2 power</span></div><div class="line">__<span class="function">device__ <span class="keyword">int</span> <span class="title">NearestPowerOf2</span> <span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</div><div class="line">  <span class="keyword">if</span> (!n) <span class="keyword">return</span> n;  <span class="comment">//(0 == 2^0)</span></div><div class="line"></div><div class="line">  <span class="keyword">int</span> x = <span class="number">1</span>;</div><div class="line">  <span class="keyword">while</span>(x &lt; n)</div><div class="line">    &#123;</div><div class="line">      x &lt;&lt;= <span class="number">1</span>;</div><div class="line">    &#125;</div><div class="line">  <span class="keyword">return</span> x;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// GPU kernel, we know: THREADS == blockDim.x</span></div><div class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">integrate</span><span class="params">(<span class="keyword">int</span> *n, <span class="keyword">int</span> *blocks, <span class="keyword">double</span> *gsum)</span> </span>&#123;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> bid = blockDim.x * blockIdx.x + threadIdx.x;</div><div class="line">  <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</div><div class="line">  <span class="keyword">double</span> sum;</div><div class="line">  <span class="keyword">int</span> i;</div><div class="line">  <span class="keyword">int</span> nTotalThreads;</div><div class="line">  __shared__ <span class="keyword">double</span> ssum[THREADS];</div><div class="line"></div><div class="line">  sum = <span class="number">0.0</span>;</div><div class="line">  <span class="keyword">for</span> (i = bid ; i &lt; *n; i += blockDim.x * *blocks) &#123;</div><div class="line">    sum += powf(<span class="number">-1</span>, i) / (<span class="number">2</span>*i + <span class="number">1</span>);</div><div class="line">  &#125;</div><div class="line">  ssum[tid] = sum * <span class="number">4</span>;</div><div class="line">  <span class="comment">// block reduction</span></div><div class="line">  __syncthreads();</div><div class="line">  nTotalThreads = NearestPowerOf2(blockDim.x/<span class="number">2</span>);</div><div class="line">  <span class="keyword">for</span> (i = nTotalThreads; i &gt; <span class="number">0</span>; i &gt;&gt;= <span class="number">1</span>) &#123; <span class="comment">/* per block */</span></div><div class="line">    <span class="keyword">if</span> (tid &lt; i)</div><div class="line">      <span class="keyword">if</span>(tid+i &lt; blockDim.x)</div><div class="line">        ssum[tid] += ssum[tid + i];</div><div class="line">    __syncthreads();</div><div class="line">  &#125;</div><div class="line">  gsum[bid] = ssum[tid];</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// number of threads must be a power of 2</span></div><div class="line">__<span class="function">global__ <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">global_reduce</span><span class="params">(<span class="keyword">int</span> *n, <span class="keyword">int</span> *blocks, <span class="keyword">double</span> *gsum)</span></span></div><div class="line"><span class="function"></span>&#123;</div><div class="line">    __shared__ <span class="keyword">double</span> ssum[THREADS];</div><div class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> tid = threadIdx.x;</div><div class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> i;</div><div class="line">    <span class="keyword">int</span> nTotalThreads;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (tid &lt; *blocks)</div><div class="line">      ssum[tid] = gsum[tid * THREADS];</div><div class="line">    <span class="keyword">else</span></div><div class="line">      ssum[tid] = <span class="number">0.0</span>;</div><div class="line">    __syncthreads();</div><div class="line">    nTotalThreads = NearestPowerOf2(blockDim.x/<span class="number">2</span>);</div><div class="line">    <span class="keyword">for</span> (i = nTotalThreads; i &gt; <span class="number">0</span>; i &gt;&gt;= <span class="number">1</span>) &#123; <span class="comment">/* per block */</span></div><div class="line">        <span class="keyword">if</span> (tid &lt; i)</div><div class="line">          <span class="keyword">if</span>(tid+i &lt; blockDim.x)</div><div class="line">            ssum[tid] += ssum[tid + i];</div><div class="line">        __syncthreads();</div><div class="line">    &#125;</div><div class="line">    gsum[tid] = ssum[tid];</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span> </span>&#123;</div><div class="line">  <span class="keyword">int</span> n, blocks;</div><div class="line">  <span class="keyword">int</span> *n_d, *blocks_d; <span class="comment">// device copy</span></div><div class="line">  <span class="keyword">double</span> PI25DT = <span class="number">3.141592653589793238462643</span>;</div><div class="line">  <span class="keyword">double</span> pi;</div><div class="line">  <span class="keyword">double</span> *mypi_d; <span class="comment">// device copy of pi</span></div><div class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">startwtime</span>, <span class="title">endwtime</span>, <span class="title">diffwtime</span>;</span></div><div class="line"></div><div class="line">  <span class="comment">// Allocate memory on GPU</span></div><div class="line">  cudaMalloc( (<span class="keyword">void</span> **) &amp;n_d, <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * <span class="number">1</span> );</div><div class="line">  cudaMalloc( (<span class="keyword">void</span> **) &amp;blocks_d, <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * <span class="number">1</span> );</div><div class="line">  cudaMalloc( (<span class="keyword">void</span> **) &amp;mypi_d, <span class="keyword">sizeof</span>(<span class="keyword">double</span>) * THREADS * MAX_BLOCKS );</div><div class="line"></div><div class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Enter the number of intervals: (0 quits) "</span>);fflush(<span class="built_in">stdout</span>);</div><div class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;n);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"Enter the number of blocks: (&lt;=%d) "</span>, MAX_BLOCKS);fflush(<span class="built_in">stdout</span>);</div><div class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;blocks);</div><div class="line"></div><div class="line">    gettimeofday(&amp;startwtime, <span class="literal">NULL</span>);</div><div class="line">    <span class="keyword">if</span> (n == <span class="number">0</span> || blocks &gt; MAX_BLOCKS)</div><div class="line">      <span class="keyword">break</span>;</div><div class="line"></div><div class="line">    <span class="comment">// copy from CPU to GPU</span></div><div class="line">    cudaMemcpy( n_d, &amp;n, <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * <span class="number">1</span>, cudaMemcpyHostToDevice );</div><div class="line">    cudaMemcpy( blocks_d, &amp;blocks, <span class="keyword">sizeof</span>(<span class="keyword">int</span>) * <span class="number">1</span>, cudaMemcpyHostToDevice );</div><div class="line"></div><div class="line">    integrate&lt;&lt;&lt; blocks, THREADS &gt;&gt;&gt;(n_d, blocks_d, mypi_d);</div><div class="line">    <span class="keyword">if</span> (blocks &gt; <span class="number">1</span>)</div><div class="line">      global_reduce&lt;&lt;&lt; <span class="number">1</span>, <span class="number">512</span> &gt;&gt;&gt;(n_d, blocks_d, mypi_d);</div><div class="line">    <span class="comment">// copy back from GPU to CPU</span></div><div class="line">    cudaMemcpy( &amp;pi, mypi_d, <span class="keyword">sizeof</span>(<span class="keyword">double</span>) * <span class="number">1</span>, cudaMemcpyDeviceToHost );</div><div class="line"></div><div class="line">    gettimeofday(&amp;endwtime, <span class="literal">NULL</span>);</div><div class="line">    MINUS_UTIME(diffwtime, endwtime, startwtime);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"pi is approximately %.16f, Error is %.16f\n"</span>,</div><div class="line">	   pi, <span class="built_in">fabs</span>(pi - PI25DT));</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"wall clock time = %d.%06d\n"</span>,</div><div class="line">	   diffwtime.tv_sec, diffwtime.tv_usec);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// free GPU memory</span></div><div class="line">  cudaFree(n_d);</div><div class="line">  cudaFree(mypi_d);</div><div class="line"></div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/parallel-system/">parallel system</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://vulture29.github.io/2017/09/22/并行系统学习之路3/" data-title="并行系统学习之路（三） ---- CUDA学习 | Xingyao Huang&#39;s Blog" data-tsina="" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2017/10/03/并行系统学习之路4/" title="并行系统学习之路（四） ---- OpenMP学习">
  <strong>上一篇：</strong><br/>
  <span>
  并行系统学习之路（四） ---- OpenMP学习</span>
</a>
</div>


<div class="next">
<a href="/2017/09/08/socket基本用法/"  title="socket基本用法">
 <strong>下一篇：</strong><br/> 
 <span>socket基本用法
</span>
</a>
</div>

</nav>

	

<section id="comments" class="comment">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/parallel-system/" title="parallel system">parallel system<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/network/" title="network">network<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/tools/" title="tools">tools<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/algorithm/" title="algorithm">algorithm<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="http://xingyaohuang.com/prog2/" target="_blank" title="看个球">看个球</a>
            
          </li>
        
          <li>
            
            	<a href="http://huihuiloves.me" target="_blank" title="网站">网站</a>
            
          </li>
        
    </ul>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m Xingyao Huang. <br/>
			</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/5981969306" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/vulture29" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		<a href="https://www.linkedin.com/in/xingyaohuang" target="_blank" class="icon-linkedin" title="linkedin"></a>
		
		
		
		
		
		<a href="mailto:huangyy1995@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2017 
		
		<a href="/about" target="_blank" title="Xingyao Huang">Xingyao Huang</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>




<script type="text/javascript">

var disqus_shortname = 'vulture29-github-io';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>






<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-106199480-1', 'auto');  
ga('send', 'pageview');
</script>





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
